{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Q= Generate a list of 100 integers containing values between 90 to 130 and store it in the variable `int_list`.After generating the list, >ind the following:"
      ],
      "metadata": {
        "id": "FyLvIcMkBY93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "int_list = [random.randint(90, 130) for _ in range(100)]"
      ],
      "metadata": {
        "id": "EOpXS2J6Bi0c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (i) Write a Python function to calculate the mean of a given list of numbers.Create a function to find the median of a list of numbers."
      ],
      "metadata": {
        "id": "BVYogEs4Bknn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mean(numbers):\n",
        "    return sum(numbers) / len(numbers)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# median\n",
        "def calculate_median(numbers):\n",
        "    sorted_numbers = sorted(numbers)\n",
        "    mid_index = len(sorted_numbers) // 2\n",
        "    if len(sorted_numbers) % 2 == 0:\n",
        "        return (sorted_numbers[mid_index - 1] + sorted_numbers[mid_index]) / 2\n",
        "    else:\n",
        "        return sorted_numbers[mid_index]"
      ],
      "metadata": {
        "id": "naOP-zUBBqc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (ii) Develop a program to compute the mode of a list of integers.\n"
      ],
      "metadata": {
        "id": "BB6jTyECBtYR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mode(numbers):\n",
        "    from collections import Counter\n",
        "    counter = Counter(numbers)\n",
        "    mode = max(counter, key=counter.get)\n",
        "    return mode"
      ],
      "metadata": {
        "id": "UgjRZo4gB02S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (iii) Implement a function to calculate the weighted mean of a list of values and their corresponding weights."
      ],
      "metadata": {
        "id": "4WHs-U6AB1YR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_weighted_mean(values, weights):\n",
        "    weighted_sum = sum(value * weight for value, weight in zip(values, weights))\n",
        "    total_weights = sum(weights)\n",
        "    return weighted_sum / total_weights"
      ],
      "metadata": {
        "id": "pVjKnr0DB5Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (iv) Write a Python function to find the geometric mean of a list of positive numbers.\n",
        "\n"
      ],
      "metadata": {
        "id": "4fBZ5lDjB54V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_geometric_mean(numbers):\n",
        "    product = 1\n",
        "    for number in numbers:\n",
        "        product *= number\n",
        "    return product ** (1 / len(numbers))"
      ],
      "metadata": {
        "id": "ncBlgME2B8uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (v) Create a program to calculate the harmonic mean of a list of values.\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "0pPvJPbYB9QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_harmonic_mean(numbers):\n",
        "    reciprocals_sum = sum(1 / number for number in numbers)\n",
        "    return len(numbers) / reciprocals_sum"
      ],
      "metadata": {
        "id": "GL25LdEYB_f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (vi) Build a function to determine the midrange of a list of numbers (average of the minimum and maximum).\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "vtoGcZGAB_1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_midrange(numbers):\n",
        "    return (min(numbers) + max(numbers)) / 2"
      ],
      "metadata": {
        "id": "FG2kMhv3CCEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (vii) Implement a Python program to find the trimmed mean of a list, excluding a certain percentage ofoutliers."
      ],
      "metadata": {
        "id": "FDnTx9WACCad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_trimmed_mean(numbers, trim_percent):\n",
        "    sorted_numbers = sorted(numbers)\n",
        "    trim_index = int(len(sorted_numbers) * trim_percent / 2)\n",
        "    trimmed_numbers = sorted_numbers[trim_index:-trim_index]\n",
        "    return calculate_mean(trimmed_numbers)"
      ],
      "metadata": {
        "id": "FxbLdzCYCDgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  2. Generate a list o> 500 integers containing values between 200 to 300 and store it in the variable `int_list2`.After generating the list, find the following:\n"
      ],
      "metadata": {
        "id": "42i_k--bCf_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "int_list2 = [random.randint(200, 300) for _ in range(500)]"
      ],
      "metadata": {
        "id": "Lm7VIkjwCu_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (i) Compare the given list of visualization for the given data:\n",
        "\n",
        "    \n",
        "\n",
        "   -  1. Frequency & Gaussian distribution\n",
        "\n",
        "   -  2. Frequency smoothened KDE plot\n",
        "\n",
        "   -  3. Gaussian distribution & smoothened KDE plot\n",
        "\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "GHZctisyCwWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Frequency & Gaussian distribution\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(int_list2, kde=False, bins=30)\n",
        "plt.title(\"Frequency Distribution\")\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.kdeplot(int_list2, fill=True)\n",
        "plt.title(\"Gaussian Distribution (KDE)\")\n",
        "plt.show()\n",
        "\n",
        "# Frequency smoothened KDE plot\n",
        "sns.histplot(int_list2, kde=True, bins=30)\n",
        "plt.title(\"Frequency & Smoothed KDE\")\n",
        "plt.show()\n",
        "\n",
        "# Gaussian distribution & smoothened KDE plot\n",
        "sns.kdeplot(int_list2, fill=True)\n",
        "plt.title(\"Gaussian Distribution (KDE)\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PaTN6gsJC3VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (ii) Write a Python function to calculate the range of a given list of numbers.\n"
      ],
      "metadata": {
        "id": "h3AJdJ9kC36E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range(numbers):\n",
        "    return max(numbers) - min(numbers)"
      ],
      "metadata": {
        "id": "T91hEs0YC6Ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###   (iii) Create a program to find the variance and standard deviation of a list of numbers.\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "ziYWUcxnC6rE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def calculate_variance(numbers):\n",
        "    return np.var(numbers)\n",
        "\n",
        "def calculate_standard_deviation(numbers):\n",
        "    return np.std(numbers)"
      ],
      "metadata": {
        "id": "ZOe6zuQaC8oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  (iv) Implement a function to compute the interquartile range (IQR) of a list of values.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CQoSE3ClC9Ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_iqr(numbers):\n",
        "    q1 = np.quantile(numbers, 0.25)\n",
        "    q3 = np.quantile(numbers, 0.75)\n",
        "    return q3 - q1"
      ],
      "metadata": {
        "id": "b3dXGBbwC-uT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (v) Build a program to calculate the coefficient of variation for a dataset.\n",
        "\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "6CAppJ4vC_GE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_coefficient_of_variation(numbers):\n",
        "    return np.std(numbers) / np.mean(numbers)"
      ],
      "metadata": {
        "id": "HUVdvfyLDAvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (vi) Write a Python function to find the mean absolute deviation (MAD) of a list of numbers.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hvn_STBpDBYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_mad(numbers):\n",
        "    mean = np.mean(numbers)\n",
        "    return np.mean(np.abs(numbers - mean))"
      ],
      "metadata": {
        "id": "WHPh4OaHDDkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (vii) Create a program to calculate the quartile deviation of a list of values.\n",
        "\n",
        "  \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "5xK2ogQ3DD79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_quartile_deviation(numbers):\n",
        "    return calculate_iqr(numbers) / 2"
      ],
      "metadata": {
        "id": "YI7kZOWODF7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (viii) Implement a function to find the range-based coefficient of dispersion for a dataset."
      ],
      "metadata": {
        "id": "i3sgj8S2DGhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_range_based_coefficient_of_dispersion(numbers):\n",
        "    return calculate_range(numbers) / (max(numbers) + min(numbers))"
      ],
      "metadata": {
        "id": "oLXnMXYBDHZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Write a Python class representing a discrete random variable with methods to calculate its expected value and variance"
      ],
      "metadata": {
        "id": "KbhTFZfOD4Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class DiscreteRandomVariable:\n",
        "    def __init__(self, values, probabilities):\n",
        "        self.values = np.array(values)\n",
        "        self.probabilities = np.array(probabilities)\n",
        "\n",
        "    def expected_value(self):\n",
        "        return np.sum(self.values * self.probabilities)\n",
        "\n",
        "    def variance(self):\n",
        "        expected_value = self.expected_value()\n",
        "        return np.sum((self.values - expected_value)**2 * self.probabilities)"
      ],
      "metadata": {
        "id": "HFG6-tO5Dh9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Implement a program to simulate the rolling o6 a 6air six-sided die and calculate the expected value and variance o6 the outcomes."
      ],
      "metadata": {
        "id": "5Ty80c0kD9mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def simulate_die_rolls(num_rolls):\n",
        "    rolls = [random.randint(1, 6) for _ in range(num_rolls)]\n",
        "    return rolls\n",
        "\n",
        "num_rolls = 10000\n",
        "rolls = simulate_die_rolls(num_rolls)\n",
        "\n",
        "sample_mean = np.mean(rolls)\n",
        "sample_variance = np.var(rolls)\n",
        "\n",
        "print(\"Sample Mean:\", sample_mean)\n",
        "print(\"Sample Variance:\", sample_variance)"
      ],
      "metadata": {
        "id": "ag0VsPmED1qc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Create a Python 6unction to generate random samples 6rom a given probabilites distribution (e.g.,binomial, Poisson) and calculate their mean and variance"
      ],
      "metadata": {
        "id": "H8tiJxmaEVlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import binom, poisson\n",
        "\n",
        "def generate_random_samples(distribution, params, num_samples):\n",
        "    if distribution == \"binomial\":\n",
        "        samples = binom.rvs(*params, size=num_samples)\n",
        "    elif distribution == \"poisson\":\n",
        "        samples = poisson.rvs(*params, size=num_samples)\n",
        "    else:\n",
        "        raise ValueError(\"Invalid distribution\")\n",
        "\n",
        "    return samples\n",
        "\n",
        "# Example usage:\n",
        "num_samples = 1000\n",
        "binomial_samples = generate_random_samples(\"binomial\", (10, 0.3), num_samples)\n",
        "poisson_samples = generate_random_samples(\"poisson\", (5,), num_samples)\n",
        "\n",
        "print(\"Binomial Sample Mean:\", np.mean(binomial_samples))\n",
        "print(\"Binomial Sample Variance:\", np.var(binomial_samples))\n",
        "print(\"Poisson Sample Mean:\", np.mean(poisson_samples))\n",
        "print(\"Poisson Sample Variance:\", np.var(poisson_samples))"
      ],
      "metadata": {
        "id": "D7IGCzIwEVVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write a Python script to generate random numbers 6rom a Gaussian (normal) distribution and compute the mean, variance, and standard deviation o6 the samples."
      ],
      "metadata": {
        "id": "3WJOh9dBERwX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from scipy.stats import norm\n",
        "\n",
        "def generate_gaussian_samples(mean, std_dev, num_samples):\n",
        "    samples = norm.rvs(loc=mean, scale=std_dev, size=num_samples)\n",
        "    return samples\n",
        "\n",
        "# Example usage:\n",
        "mean = 50\n",
        "std_dev = 10\n",
        "num_samples = 1000\n",
        "gaussian_samples = generate_gaussian_samples(mean, std_dev, num_samples)\n",
        "\n",
        "print(\"Gaussian Sample Mean:\", np.mean(gaussian_samples))\n",
        "print(\"Gaussian Sample Variance:\", np.var(gaussian_samples))\n",
        "print(\"Gaussian Sample Standard Deviation:\", np.std(gaussian_samples))"
      ],
      "metadata": {
        "id": "XQl3xw_9EDO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3w3iKGauEGXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use seaborn librares to load tips dataset. Find the 6ollowing 6rom the dataset 6or the columns total_bill and tip`:"
      ],
      "metadata": {
        "id": "olhuQS0DEx7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the 'tips' dataset\n",
        "tips_df = sns.load_dataset(\"tips\")"
      ],
      "metadata": {
        "id": "IRjPSauJEu-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###    Write a Python function that calculates their skewness"
      ],
      "metadata": {
        "id": "gKJ5fYGEE-fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_skewness(data):\n",
        "    return data.skew()\n",
        "\n",
        "total_bill_skewness = calculate_skewness(tips_df[\"total_bill\"])\n",
        "tip_skewness = calculate_skewness(tips_df[\"tip\"])\n",
        "\n",
        "print(\"Skewness of total_bill:\", total_bill_skewness)\n",
        "print(\"Skewness of tip:\", tip_skewness)"
      ],
      "metadata": {
        "id": "m6eWhFJZEvmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###    Create a program that determunes whether the columns exhibit positive skewness, negative skewness, or is approximately symmetric.\n",
        "\n"
      ],
      "metadata": {
        "id": "ZkMEbIjFFG21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def determine_skewness_type(skewness):\n",
        "    if skewness > 0:\n",
        "        return \"Positively skewed\"\n",
        "    elif skewness < 0:\n",
        "        return \"Negatively skewed\"\n",
        "    else:\n",
        "        return \"Approximately symmetric\"\n",
        "\n",
        "total_bill_skewness_type = determine_skewness_type(total_bill_skewness)\n",
        "tip_skewness_type = determine_skewness_type(tip_skewness)\n",
        "\n",
        "print(\"Skewness type of total_bill:\", total_bill_skewness_type)\n",
        "print(\"Skewness type of tip:\", tip_skewness_type)"
      ],
      "metadata": {
        "id": "_517GWd0E4Ty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Write a function that calculates the covariance between two columns.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qykUqvodFR6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_covariance(column1, column2):\n",
        "    return np.cov(column1, column2)[0, 1]\n",
        "\n",
        "covariance = calculate_covariance(tips_df[\"total_bill\"], tips_df[\"tip\"])\n",
        "print(\"Covariance:\", covariance)\n",
        "\n",
        "def calculate_correlation(column1, column2):\n",
        "    return np.corrcoef(column1, column2)[0, 1]\n",
        "\n",
        "correlation = calculate_correlation(tips_df[\"total_bill\"], tips_df[\"tip\"])\n",
        "print(\"Correlation:\", correlation)"
      ],
      "metadata": {
        "id": "rbIp7usWFhw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ### Implement a Python program that calculates the Pearson correlation coefficient between two columns.\n",
        "\n"
      ],
      "metadata": {
        "id": "oEqba6SnFiJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_correlation(column1, column2, df):\n",
        "    plt.scatter(df[column1], df[column2])\n",
        "    plt.xlabel(column1)\n",
        "    plt.ylabel(column2)\n",
        "    plt.title(f\"{column1} vs. {column2}\")\n",
        "    plt.show()\n",
        "\n",
        "visualize_correlation(\"total_bill\", \"tip\", tips_df)"
      ],
      "metadata": {
        "id": "jTLeeFJvFjj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Write a script to visualize the correlation between two specific columns in a Pandas DataFrame using scatter plots."
      ],
      "metadata": {
        "id": "m4l76bwaFj93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write a Python 6unction to calculate the probability density function (PDF) of a continuous random variable 6or a given normal distribution.\n"
      ],
      "metadata": {
        "id": "HCiMgLOEFkte"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_normal_pdf(x, mean, std_dev):\n",
        "    return norm.pdf(x, loc=mean, scale=std_dev)"
      ],
      "metadata": {
        "id": "4VXQ1x7dGfEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Â¸) Create a program to calculate the cumulative distribution 6unction (CDF) o6 exponential distribution"
      ],
      "metadata": {
        "id": "70UmKBz9GiC8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import expon\n",
        "\n",
        "def calculate_exponential_cdf(x, rate):\n",
        "    return expon.cdf(x, scale=1/rate)"
      ],
      "metadata": {
        "id": "Rw7tViIPGmPQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Write a Python 6unction to calculate the probability mass 6unction (PMF) o6 Poisson distribution."
      ],
      "metadata": {
        "id": "Q2rktcjeGsgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import poisson\n",
        "\n",
        "def calculate_poisson_pmf(k, rate):\n",
        "    return poisson.pmf(k, mu=rate)"
      ],
      "metadata": {
        "id": "tHwPi2LGGpeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A company wants to test iN a new website layout leads to a higher conversion rate (percentage oN visitors who make a purchase). They collect data Nrom the old and new layouts to compare.\n"
      ],
      "metadata": {
        "id": "GQ9_G7lDHIA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "old_layout = np.array([1] * 50 + [0] * 950)\n",
        "new_layout = np.array([1] * 70 + [0] * 930)\n",
        "\n",
        "# Conversion rates\n",
        "p1 = np.mean(old_layout)\n",
        "p2 = np.mean(new_layout)\n",
        "\n",
        "# Sample sizes\n",
        "n1 = len(old_layout)\n",
        "n2 = len(new_layout)\n",
        "\n",
        "# Pooled proportion\n",
        "p_pool = (np.sum(old_layout) + np.sum(new_layout)) / (n1 + n2)\n",
        "\n",
        "# Standard Error\n",
        "SE = np.sqrt(p_pool * (1 - p_pool) * (1/n1 + 1/n2))\n",
        "\n",
        "# Z-Statistic\n",
        "Z = (p1 - p2) / SE\n",
        "\n",
        "# p-value\n",
        "p_value = stats.norm.sf(abs(Z)) * 2  # Two-tailed test\n",
        "\n",
        "print(f\"Z-Statistic: {Z}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the two layouts.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the two layouts.\")\n"
      ],
      "metadata": {
        "id": "e5egN4vmGrl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A tutoring service claims that its program improves students' exam scores. A sample oN students who participated in the program was taken, and their scores beNore and aNter the program were recorded.\n"
      ],
      "metadata": {
        "id": "TdEE2RXNHYAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "before_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])\n",
        "after_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])\n",
        "\n",
        "# Means\n",
        "mean_before = np.mean(before_program)\n",
        "mean_after = np.mean(after_program)\n",
        "\n",
        "# Variances (using sample variances for z-test approximation)\n",
        "var_before = np.var(before_program, ddof=1)\n",
        "var_after = np.var(after_program, ddof=1)\n",
        "\n",
        "# Sample sizes\n",
        "n = len(before_program)\n",
        "\n",
        "# Standard error of the difference in means\n",
        "SE = np.sqrt((var_before / n) + (var_after / n))\n",
        "\n",
        "# Z-Statistic\n",
        "Z = (mean_after - mean_before) / SE\n",
        "\n",
        "# p-value (two-tailed test)\n",
        "p_value = stats.norm.sf(abs(Z)) * 2\n",
        "\n",
        "print(f\"Z-Statistic: {Z}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in scores before and after the program.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in scores before and after the program.\")\n"
      ],
      "metadata": {
        "id": "9S8mzRFsHE4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A pharmaceutical company wants to determine iN a new drug is eNNective in reducing blood pressure. They conduct a study and record blood pressure measurements beNore and aNter administering the drug.\n"
      ],
      "metadata": {
        "id": "FN9tsB0THj87"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "before_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])\n",
        "after_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])\n",
        "\n",
        "# Means\n",
        "mean_before = np.mean(before_drug)\n",
        "mean_after = np.mean(after_drug)\n",
        "\n",
        "# Variances (using sample variances for z-test approximation)\n",
        "var_before = np.var(before_drug, ddof=1)\n",
        "var_after = np.var(after_drug, ddof=1)\n",
        "\n",
        "# Sample sizes\n",
        "n = len(before_drug)\n",
        "\n",
        "# Standard error of the difference in means\n",
        "SE = np.sqrt((var_before / n) + (var_after / n))\n",
        "\n",
        "# Z-Statistic\n",
        "Z = (mean_before - mean_after) / SE\n",
        "\n",
        "# p-value (two-tailed test)\n",
        "p_value = stats.norm.sf(abs(Z)) * 2\n",
        "\n",
        "print(f\"Z-Statistic: {Z}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The drug has a significant effect in reducing blood pressure.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The drug does not have a significant effect in reducing blood pressure.\")\n"
      ],
      "metadata": {
        "id": "XE5o3iSrHeiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  A customer service department claims that their average response time is less than 5 minutes V A sample of recent customer interactions was taken, and the response times were recorded.\n"
      ],
      "metadata": {
        "id": "_SD2QEeDHujU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Data\n",
        "response_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])\n",
        "\n",
        "# Parameters\n",
        "claimed_mean = 5\n",
        "\n",
        "# Sample statistics\n",
        "sample_mean = np.mean(response_times)\n",
        "sample_std = np.std(response_times, ddof=1)\n",
        "sample_size = len(response_times)\n",
        "\n",
        "# Standard Error\n",
        "SE = sample_std / np.sqrt(sample_size)\n",
        "\n",
        "# Z-Statistic\n",
        "Z = (sample_mean - claimed_mean) / SE\n",
        "\n",
        "# p-value (one-tailed test)\n",
        "p_value = stats.norm.cdf(Z)  # Lower tail test\n",
        "\n",
        "print(f\"Z-Statistic: {Z}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The average response time is significantly less than 5 minutes.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is not enough evidence to claim the average response time is less than 5 minutes.\")\n"
      ],
      "metadata": {
        "id": "UzAgai9OHpiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A company is testing two different website layouts to see which one leads to higher click-through ratesV Write a Python function to perfor: an A/B test analysis, including calculating the t-statistic, degrees of freedom, and p-value.\n"
      ],
      "metadata": {
        "id": "DsI9O4UFH-6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def ab_test_analysis(layout_a_clicks, layout_b_clicks):\n",
        "    # Convert lists to numpy arrays\n",
        "    layout_a_clicks = np.array(layout_a_clicks)\n",
        "    layout_b_clicks = np.array(layout_b_clicks)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_a = np.mean(layout_a_clicks)\n",
        "    mean_b = np.mean(layout_b_clicks)\n",
        "\n",
        "    # Calculate variances\n",
        "    var_a = np.var(layout_a_clicks, ddof=1)\n",
        "    var_b = np.var(layout_b_clicks, ddof=1)\n",
        "\n",
        "    # Calculate sample sizes\n",
        "    n_a = len(layout_a_clicks)\n",
        "    n_b = len(layout_b_clicks)\n",
        "\n",
        "    # Calculate the standard error of the difference in means\n",
        "    SE = np.sqrt((var_a / n_a) + (var_b / n_b))\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = (mean_a - mean_b) / SE\n",
        "\n",
        "    # Calculate degrees of freedom\n",
        "    df = ((var_a / n_a + var_b / n_b) ** 2) / \\\n",
        "         (((var_a / n_a) ** 2 / (n_a - 1)) + ((var_b / n_b) ** 2 / (n_b - 1)))\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Data\n",
        "layout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]\n",
        "layout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]\n",
        "\n",
        "# Perform A/B test analysis\n",
        "t_statistic, df, p_value = ab_test_analysis(layout_a_clicks, layout_b_clicks)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference between the click-through rates of the two layouts.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference between the click-through rates of the two layouts.\")\n"
      ],
      "metadata": {
        "id": "1vPMiz6DH56c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A pharmaceutical co:pany wants to determine if a new drug is more effective than an existing drug in reducing cholesterol levelsV Create a program to analyze the clinical trial data and calculate the tstatistic and p-value for the treatment effect.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Se-0alJOINR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_drug_effect(existing_drug_levels, new_drug_levels):\n",
        "    # Convert lists to numpy arrays\n",
        "    existing_drug_levels = np.array(existing_drug_levels)\n",
        "    new_drug_levels = np.array(new_drug_levels)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_existing = np.mean(existing_drug_levels)\n",
        "    mean_new = np.mean(new_drug_levels)\n",
        "\n",
        "    # Calculate variances\n",
        "    var_existing = np.var(existing_drug_levels, ddof=1)\n",
        "    var_new = np.var(new_drug_levels, ddof=1)\n",
        "\n",
        "    # Calculate sample sizes\n",
        "    n_existing = len(existing_drug_levels)\n",
        "    n_new = len(new_drug_levels)\n",
        "\n",
        "    # Calculate the standard error of the difference in means\n",
        "    SE = np.sqrt((var_existing / n_existing) + (var_new / n_new))\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = (mean_existing - mean_new) / SE\n",
        "\n",
        "    # Calculate degrees of freedom\n",
        "    df = ((var_existing / n_existing + var_new / n_new) ** 2) / \\\n",
        "         (((var_existing / n_existing) ** 2 / (n_existing - 1)) + ((var_new / n_new) ** 2 / (n_new - 1)))\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Data\n",
        "existing_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]\n",
        "new_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]\n",
        "\n",
        "# Perform the analysis\n",
        "t_statistic, df, p_value = analyze_drug_effect(existing_drug_levels, new_drug_levels)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The new drug is significantly more effective in reducing cholesterol levels.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in effectiveness between the new drug and the existing drug.\")\n"
      ],
      "metadata": {
        "id": "Dg3Mqb_tIIUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A school district introduces an educational intervention program to improve math scores V Write a Python function to analyze pre- and post-intervention test scores, calculating the t-statistic and p-value to determine if the intervention had a significant i:pact.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VxG6oDN7IdEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_intervention(pre_intervention_scores, post_intervention_scores):\n",
        "    # Convert lists to numpy arrays\n",
        "    pre_intervention_scores = np.array(pre_intervention_scores)\n",
        "    post_intervention_scores = np.array(post_intervention_scores)\n",
        "\n",
        "    # Calculate differences\n",
        "    differences = post_intervention_scores - pre_intervention_scores\n",
        "\n",
        "    # Calculate mean and standard deviation of differences\n",
        "    mean_diff = np.mean(differences)\n",
        "    std_diff = np.std(differences, ddof=1)\n",
        "    n = len(differences)\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = mean_diff / (std_diff / np.sqrt(n))\n",
        "\n",
        "    # Degrees of freedom\n",
        "    df = n - 1\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Data\n",
        "pre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]\n",
        "post_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
        "\n",
        "# Perform the analysis\n",
        "t_statistic, df, p_value = analyze_intervention(pre_intervention_scores, post_intervention_scores)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The intervention had a significant impact on math scores.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant evidence that the intervention impacted math scores.\")\n"
      ],
      "metadata": {
        "id": "s2lc6QJFIY9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  An HR department wants to investigate i@ there's a gender-based salary gap within the company. Develop a program to analyze salary data, calculate the t-statistic, and determine i@ there's a statistically signi@icant di@@erence between the average salaries o@ male and @emale employees.\n",
        "\n"
      ],
      "metadata": {
        "id": "DhGmDRr8IqtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_salary_gap(male_salaries, female_salaries):\n",
        "    # Convert lists to numpy arrays\n",
        "    male_salaries = np.array(male_salaries)\n",
        "    female_salaries = np.array(female_salaries)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_male = np.mean(male_salaries)\n",
        "    mean_female = np.mean(female_salaries)\n",
        "\n",
        "    # Calculate variances\n",
        "    var_male = np.var(male_salaries, ddof=1)\n",
        "    var_female = np.var(female_salaries, ddof=1)\n",
        "\n",
        "    # Sample sizes\n",
        "    n_male = len(male_salaries)\n",
        "    n_female = len(female_salaries)\n",
        "\n",
        "    # Calculate the standard error of the difference in means\n",
        "    SE = np.sqrt((var_male / n_male) + (var_female / n_female))\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = (mean_male - mean_female) / SE\n",
        "\n",
        "    # Calculate degrees of freedom using Welch's approximation\n",
        "    df = ((var_male / n_male + var_female / n_female) ** 2) / \\\n",
        "         (((var_male / n_male) ** 2 / (n_male - 1)) + ((var_female / n_female) ** 2 / (n_female - 1)))\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Generate synthetic salary data\n",
        "np.random.seed(0)  # For reproducibility\n",
        "male_salaries = np.random.normal(loc=50000, scale=10000, size=20)\n",
        "female_salaries = np.random.normal(loc=55000, scale=9000, size=20)\n",
        "\n",
        "# Perform the analysis\n",
        "t_statistic, df, p_value = analyze_salary_gap(male_salaries, female_salaries)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in average salaries between male and female employees.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in average salaries between male and female employees.\")\n"
      ],
      "metadata": {
        "id": "WkB8WlS6Imr2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  A manufacturer produces two different versions of a product and wants to compare their quality scores. Create a Python function to analyze quality assessment data, calculate the t-statistic, and decide whether there's a significant difference in quality between the two versions."
      ],
      "metadata": {
        "id": "mAZ9qQXWIzoG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_quality_scores(version1_scores, version2_scores):\n",
        "    # Convert lists to numpy arrays\n",
        "    version1_scores = np.array(version1_scores)\n",
        "    version2_scores = np.array(version2_scores)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_v1 = np.mean(version1_scores)\n",
        "    mean_v2 = np.mean(version2_scores)\n",
        "\n",
        "    # Calculate variances\n",
        "    var_v1 = np.var(version1_scores, ddof=1)\n",
        "    var_v2 = np.var(version2_scores, ddof=1)\n",
        "\n",
        "    # Sample sizes\n",
        "    n_v1 = len(version1_scores)\n",
        "    n_v2 = len(version2_scores)\n",
        "\n",
        "    # Calculate the standard error of the difference in means\n",
        "    SE = np.sqrt((var_v1 / n_v1) + (var_v2 / n_v2))\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = (mean_v1 - mean_v2) / SE\n",
        "\n",
        "    # Calculate degrees of freedom using Welch's approximation\n",
        "    df = ((var_v1 / n_v1 + var_v2 / n_v2) ** 2) / \\\n",
        "         (((var_v1 / n_v1) ** 2 / (n_v1 - 1)) + ((var_v2 / n_v2) ** 2 / (n_v2 - 1)))\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Data\n",
        "version1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]\n",
        "version2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]\n",
        "\n",
        "# Perform the analysis\n",
        "t_statistic, df, p_value = analyze_quality_scores(version1_scores, version2_scores)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in quality between the two versions of the product.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in quality between the two versions of the product.\")\n"
      ],
      "metadata": {
        "id": "N98zffs5JHqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 20. A restaurant chain collects customer satisfaction scores for two different branches. Write a program to analyze the scores, calculate the t-statistic, and determine i@ there's a statistically significant difference in customer satisfaction between the branches.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y07oQguOJQqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "def analyze_satisfaction_scores(branch_a_scores, branch_b_scores):\n",
        "    # Convert lists to numpy arrays\n",
        "    branch_a_scores = np.array(branch_a_scores)\n",
        "    branch_b_scores = np.array(branch_b_scores)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_a = np.mean(branch_a_scores)\n",
        "    mean_b = np.mean(branch_b_scores)\n",
        "\n",
        "    # Calculate variances\n",
        "    var_a = np.var(branch_a_scores, ddof=1)\n",
        "    var_b = np.var(branch_b_scores, ddof=1)\n",
        "\n",
        "    # Sample sizes\n",
        "    n_a = len(branch_a_scores)\n",
        "    n_b = len(branch_b_scores)\n",
        "\n",
        "    # Calculate the standard error of the difference in means\n",
        "    SE = np.sqrt((var_a / n_a) + (var_b / n_b))\n",
        "\n",
        "    # Calculate the t-statistic\n",
        "    t_statistic = (mean_a - mean_b) / SE\n",
        "\n",
        "    # Calculate degrees of freedom using Welch's approximation\n",
        "    df = ((var_a / n_a + var_b / n_b) ** 2) / \\\n",
        "         (((var_a / n_a) ** 2 / (n_a - 1)) + ((var_b / n_b) ** 2 / (n_b - 1)))\n",
        "\n",
        "    # Calculate p-value (two-tailed test)\n",
        "    p_value = stats.t.sf(np.abs(t_statistic), df) * 2\n",
        "\n",
        "    return t_statistic, df, p_value\n",
        "\n",
        "# Data\n",
        "branch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]\n",
        "branch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]\n",
        "\n",
        "# Perform the analysis\n",
        "t_statistic, df, p_value = analyze_satisfaction_scores(branch_a_scores, branch_b_scores)\n",
        "\n",
        "print(f\"T-Statistic: {t_statistic}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in customer satisfaction between the two branches.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in customer satisfaction between the two branches.\")\n"
      ],
      "metadata": {
        "id": "UiJ5oJ3pJKm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A political analyst wants to determine if there is a significant association between age groups and voter preferences FCandidate A or Candidate B. They collect data from a sample of 500 voters and classify them into different age groups and candidate preferences. Perform a Chi-Square test to determine if there is a significant association between age groups and voter preferences.\n",
        "\n"
      ],
      "metadata": {
        "id": "7XmYpunCJeWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def chi_square_test(age_groups, voter_preferences):\n",
        "    # Create a contingency table\n",
        "    contingency_table = np.zeros((len(np.unique(age_groups)), len(np.unique(voter_preferences))))\n",
        "\n",
        "    for i, age_group in enumerate(np.unique(age_groups)):\n",
        "        for j, preference in enumerate(np.unique(voter_preferences)):\n",
        "            contingency_table[i, j] = np.sum((age_groups == age_group) & (voter_preferences == preference))\n",
        "\n",
        "    # Perform Chi-Square test\n",
        "    chi2_stat, p_value, _, _ = chi2_contingency(contingency_table, correction=False)\n",
        "\n",
        "    return chi2_stat, p_value, contingency_table\n",
        "\n",
        "# Generate data\n",
        "np.random.seed(0)\n",
        "age_groups = np.random.choice(['18-30', '31-50', '51+'], size=500)\n",
        "voter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)\n",
        "\n",
        "# Perform the Chi-Square test\n",
        "chi2_stat, p_value, contingency_table = chi_square_test(age_groups, voter_preferences)\n",
        "\n",
        "print(f\"Contingency Table:\\n{contingency_table}\")\n",
        "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant association between age groups and voter preferences.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant association between age groups and voter preferences.\")\n"
      ],
      "metadata": {
        "id": "1vXB4yjNJdWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  22. A company conducted a customer satisfaction survey to determine if there is a significant relationship between product satisfaction levels (Satisfied, Neutral, Dissatisfied) and the region where customers are located (East, West, North, South). The survey data is summarized in a contingency table. Conduct a ChiSquare test to determine if there is a significant relationship between product satisfaction levels and customer regions.\n",
        "\n"
      ],
      "metadata": {
        "id": "7UvpYMAvJ2Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def chi_square_test(data):\n",
        "    # Perform Chi-Square test\n",
        "    chi2_stat, p_value, df, expected = chi2_contingency(data, correction=False)\n",
        "\n",
        "    return chi2_stat, p_value, df, expected\n",
        "\n",
        "# Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)\n",
        "data = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])\n",
        "\n",
        "# Perform the Chi-Square test\n",
        "chi2_stat, p_value, df, expected = chi_square_test(data)\n",
        "\n",
        "print(f\"Contingency Table:\\n{data}\")\n",
        "print(f\"Expected Frequencies:\\n{expected}\")\n",
        "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant relationship between product satisfaction levels and customer regions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant relationship between product satisfaction levels and customer regions.\")\n"
      ],
      "metadata": {
        "id": "kT8KyJIiJxR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  23. A company implemented an employee training program to improve job performance (Effective, Neutral, Ineffective). After the training, they collected data from a sample of employees and classified them based on their job performance before and after the training. Perform a Chi-Square test to determine if there is a significant difference between job performance levels before and after the training.\n",
        "\n"
      ],
      "metadata": {
        "id": "0TySnI5XKCQu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "def chi_square_test(data):\n",
        "    # Perform Chi-Square test\n",
        "    chi2_stat, p_value, df, expected = chi2_contingency(data, correction=False)\n",
        "\n",
        "    return chi2_stat, p_value, df, expected\n",
        "\n",
        "# Sample data: Job performance levels before (rows) and after (columns) training\n",
        "data = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]])\n",
        "\n",
        "# Perform the Chi-Square test\n",
        "chi2_stat, p_value, df, expected = chi_square_test(data)\n",
        "\n",
        "print(f\"Contingency Table:\\n{data}\")\n",
        "print(f\"Expected Frequencies:\\n{expected}\")\n",
        "print(f\"Chi-Square Statistic: {chi2_stat}\")\n",
        "print(f\"Degrees of Freedom: {df}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in job performance levels before and after training.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in job performance levels before and after training.\")\n"
      ],
      "metadata": {
        "id": "bEuhAjldJ89C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  24. A company produces three different versions of a product: Standard, Premium, and Deluxe. The company wants to determine if there is a significant difference in customer satisfaction scores among the three product versions. They conducted a survey and collected customer satisfaction scores for each version from a random sample of customers. Perform an ANOVA test to determine if there is a significant difference in customer satisfaction scores.\n"
      ],
      "metadata": {
        "id": "VqWzLwCTKN0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "def anova_test(*args):\n",
        "    # Perform ANOVA test\n",
        "    f_statistic, p_value = f_oneway(*args)\n",
        "    return f_statistic, p_value\n",
        "\n",
        "# Sample data: Customer satisfaction scores for each product version\n",
        "standard_scores = [80, 85, 90, 78, 88, 82, 92, 78, 85, 87]\n",
        "premium_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]\n",
        "deluxe_scores = [95, 98, 92, 97, 96, 94, 98, 97, 92, 99]\n",
        "\n",
        "# Perform the ANOVA test\n",
        "f_statistic, p_value = anova_test(standard_scores, premium_scores, deluxe_scores)\n",
        "\n",
        "print(f\"F-Statistic: {f_statistic}\")\n",
        "print(f\"P-Value: {p_value}\")\n",
        "\n",
        "# Decision\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in customer satisfaction scores among the product versions.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in customer satisfaction scores among the product versions.\")\n"
      ],
      "metadata": {
        "id": "-ChKVNzDKJuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qpyGRSwJKWAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}